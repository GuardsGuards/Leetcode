{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n",
      "[1, 2]\n",
      "[0, 1]\n"
     ]
    }
   ],
   "source": [
    "class Solution(object):\n",
    "    def twoSum(self, nums, target):\n",
    "        seen = {} \n",
    "        for i, num in enumerate(nums):\n",
    "            complement = target - num\n",
    "            if complement in seen:        \n",
    "                return [seen[complement], i]\n",
    "            seen[num] = i\n",
    "        return []\n",
    "\n",
    "s = Solution()\n",
    "print(s.twoSum([2, 7, 11, 15], 9))    # [0, 1]\n",
    "print(s.twoSum([3, 2, 4], 6))         # [1, 2]\n",
    "print(s.twoSum([3, 3], 6))            # [0, 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplified Financial Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('AAPL', 'TSLA'), ('GOOG', 'AMZN'), ('META', 'NFLX')]\n"
     ]
    }
   ],
   "source": [
    "returns = [0.03, -0.01, -0.03, 0.01, 0.05, -0.05]\n",
    "tickers = ['AAPL', 'GOOG', 'TSLA', 'AMZN', 'META', 'NFLX']\n",
    "target_return = 0.00\n",
    "\n",
    "def neutral_pairs(returns, tickers, target_return, tolerance=1e-6):\n",
    "    \n",
    "    # Finds pairs of assets whose returns sum approximately to a target return.\n",
    "    \n",
    "    seen = {}\n",
    "    result = []\n",
    "\n",
    "    for i, r in enumerate(returns):\n",
    "        complement = target_return - r\n",
    "\n",
    "        # Round to avoid floating point precision issues\n",
    "        complement = round(complement, 6)\n",
    "        r_rounded = round(r, 6)\n",
    "\n",
    "        if complement in seen:\n",
    "            # Store the pair of ticker names\n",
    "            result.append((tickers[seen[complement]], tickers[i]))\n",
    "        else:\n",
    "            seen[r_rounded] = i\n",
    "\n",
    "    return result\n",
    "\n",
    "print(neutral_pairs(returns, tickers, target_return))\n",
    "# Output: [('AAPL', 'TSLA'), ('META', 'NFLX')]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expanded Financial Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to get ticker 'AAPL' reason: Failed to perform, curl: (28) Connection timed out after 10001 milliseconds. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.\n",
      "[*********************100%***********************]  8 of 8 completed\n",
      "\n",
      "7 Failed downloads:\n",
      "['BHP']: Timeout('Failed to perform, curl: (28) Connection timed out after 10004 milliseconds. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.')\n",
      "['AAPL']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "['PG']: Timeout('Failed to perform, curl: (28) Operation timed out after 10014 milliseconds with 5815 bytes received. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.')\n",
      "['JNJ']: Timeout('Failed to perform, curl: (28) Connection timed out after 10012 milliseconds. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.')\n",
      "['TSLA']: Timeout('Failed to perform, curl: (28) Operation timed out after 10006 milliseconds with 1959 bytes received. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.')\n",
      "['GE']: Timeout('Failed to perform, curl: (28) Operation timed out after 10004 milliseconds with 19495 bytes received. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.')\n",
      "['GOOG']: Timeout('Failed to perform, curl: (28) Operation timed out after 10002 milliseconds with 40555 bytes received. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.')\n",
      "C:\\Users\\noah.woltman\\AppData\\Local\\Temp\\ipykernel_15984\\2145007706.py:21: FutureWarning: The default fill_method='pad' in DataFrame.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  returns = prices.pct_change().dropna()\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Diversified ticker set\n",
    "tickers = ['AAPL', 'GOOG', 'TSLA', 'NVDA',  # Tech\n",
    "           'GE',                           # Industrial\n",
    "           'JNJ',                          # Healthcare\n",
    "           'PG',                           # Consumer\n",
    "           'BHP']                          # Mining\n",
    "\n",
    "# Save to CSV to avoid re-downloading\n",
    "data_path = \"cached_prices.csv\"\n",
    "\n",
    "if os.path.exists(data_path):\n",
    "    prices = pd.read_csv(data_path, index_col=0, parse_dates=True)\n",
    "else:\n",
    "    prices = yf.download(tickers, start=\"2018-01-01\")['Adj Close']\n",
    "    prices.to_csv(data_path)\n",
    "\n",
    "returns = prices.pct_change().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Example (most recent date):\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m recent = \u001b[43mreturns\u001b[49m\u001b[43m.\u001b[49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(neutral_pairs(recent.tolist(), returns.columns.tolist(), \u001b[32m0.0\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\noah.woltman\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexing.py:1191\u001b[39m, in \u001b[36m_LocationIndexer.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1189\u001b[39m maybe_callable = com.apply_if_callable(key, \u001b[38;5;28mself\u001b[39m.obj)\n\u001b[32m   1190\u001b[39m maybe_callable = \u001b[38;5;28mself\u001b[39m._check_deprecated_callable_usage(key, maybe_callable)\n\u001b[32m-> \u001b[39m\u001b[32m1191\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\noah.woltman\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexing.py:1752\u001b[39m, in \u001b[36m_iLocIndexer._getitem_axis\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCannot index by location index with a non-integer key\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1751\u001b[39m \u001b[38;5;66;03m# validate the location\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1752\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_integer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1754\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.obj._ixs(key, axis=axis)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\noah.woltman\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexing.py:1685\u001b[39m, in \u001b[36m_iLocIndexer._validate_integer\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1683\u001b[39m len_axis = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.obj._get_axis(axis))\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m key >= len_axis \u001b[38;5;129;01mor\u001b[39;00m key < -len_axis:\n\u001b[32m-> \u001b[39m\u001b[32m1685\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33msingle positional indexer is out-of-bounds\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mIndexError\u001b[39m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "def neutral_pairs(returns, tickers, target_return=0.0, tolerance=1e-6):\n",
    "    seen = {}\n",
    "    result = []\n",
    "\n",
    "    for i, r in enumerate(returns):\n",
    "        complement = round(target_return - r, 6)\n",
    "        r_rounded = round(r, 6)\n",
    "        if abs(complement - r_rounded) < tolerance and complement in seen:\n",
    "            result.append((tickers[seen[complement]], tickers[i]))\n",
    "        else:\n",
    "            seen[r_rounded] = i\n",
    "    return result\n",
    "\n",
    "# Example (most recent date):\n",
    "recent = returns.iloc[-1]\n",
    "print(neutral_pairs(recent.tolist(), returns.columns.tolist(), 0.0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Financial Application\n",
    "\n",
    "#### rolling covariance weighted hedging tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.mstats import winsorize\n",
    "import numpy as np\n",
    "\n",
    "# Winsorize returns to reduce impact of outliers\n",
    "winsorized_returns = returns.apply(lambda x: pd.Series(winsorize(x, limits=[0.1, 0.1]).data, index=x.index))\n",
    "\n",
    "# Basic correlation matrix (Pearson)\n",
    "corr_matrix = winsorized_returns.corr()\n",
    "vols = winsorized_returns.std()\n",
    "\n",
    "# Stress definition and filtering\n",
    "stress_days = (returns < -0.05).any(axis=1)\n",
    "corr_during_stress = winsorized_returns[stress_days].corr()\n",
    "\n",
    "def pair_score(a, b, alpha=0.6, beta=0.3, gamma=0.1):\n",
    "    c1 = corr_matrix.loc[a, b]\n",
    "    c2 = 1 - corr_during_stress.loc[a, b]\n",
    "    vol_ratio = abs(vols[a] - vols[b])\n",
    "    return alpha * c1 + beta * c2 - gamma * vol_ratio\n",
    "\n",
    "def find_low_corr_pairs(thresh=0.3):\n",
    "    pairs = []\n",
    "    for i, a in enumerate(corr_matrix.columns):\n",
    "        for j in range(i + 1, len(corr_matrix.columns)):\n",
    "            b = corr_matrix.columns[j]\n",
    "            c = corr_matrix.loc[a, b]\n",
    "            if abs(c) < thresh:\n",
    "                score = pair_score(a, b)\n",
    "                pairs.append((a, b, c, score))\n",
    "    return sorted(pairs, key=lambda x: x[3])\n",
    "\n",
    "# Print top low-correlation pairs\n",
    "low_corr_pairs = find_low_corr_pairs()\n",
    "for p in low_corr_pairs:\n",
    "    print(f\"Pair: {p[0]} & {p[1]} | Corr: {p[2]:.3f} | Score: {p[3]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'yfinance'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01myfinance\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01myf\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Download historical prices\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'yfinance'"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# Download historical prices\n",
    "tickers = ['AAPL', 'GOOG', 'TSLA', 'AMZN', 'META', 'NFLX']\n",
    "prices = yf.download(tickers, start=\"2024-06-01\", end=\"2025-06-01\")['Adj Close']\n",
    "returns = prices.pct_change().dropna()\n",
    "\n",
    "# === TwoSum: Return-neutral pair detection === #\n",
    "def TwoSum(tickers, returns, target_return=0.0, tolerance=1e-4):\n",
    "    seen = {}\n",
    "    result = []\n",
    "    for i, r in enumerate(returns):\n",
    "        complement = round(target_return - r, 6)\n",
    "        r_rounded = round(r, 6)\n",
    "        if complement in seen:\n",
    "            result.append((tickers[seen[complement]], tickers[i]))\n",
    "        else:\n",
    "            seen[r_rounded] = i\n",
    "    return result\n",
    "\n",
    "# === Apply TwoSum to each day's returns === #\n",
    "def rolling_neutral_pairs(returns_df, target_return=0.0, tolerance=1e-4):\n",
    "    results = []\n",
    "    for date, row in returns_df.iterrows():\n",
    "        result = TwoSum(returns_df.columns.tolist(), row.tolist(), target_return, tolerance)\n",
    "        results.append((date, result))\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# Download historical prices\n",
    "tickers = ['AAPL', 'GOOG', 'TSLA', 'AMZN', 'META', 'NFLX']\n",
    "prices = yf.download(tickers, start=\"2024-06-01\", end=\"2025-06-01\")['Adj Close']\n",
    "returns = prices.pct_change().dropna()\n",
    "\n",
    "# === Compute correlation matrices and volatilities === #\n",
    "corr_matrix = returns.corr()\n",
    "vols = returns.std()\n",
    "\n",
    "# Identify stress periods: days where any asset drops more than 5%\n",
    "drawdowns = (returns < -0.05).any(axis=1)\n",
    "\n",
    "# Correlation matrix during stress periods\n",
    "corr_during_stress = returns[drawdowns].corr()\n",
    "\n",
    "# === Optional filters === #\n",
    "def passes_corr_filter(a, b, threshold=0.6):\n",
    "    return corr_matrix.loc[a, b] > threshold\n",
    "\n",
    "def stress_inverted_filter(a, b, max_corr=0.2):\n",
    "    return corr_during_stress.loc[a, b] < max_corr\n",
    "\n",
    "# === Pair scoring based on normal and stress correlation + volatility divergence === #\n",
    "def pair_score(a, b, alpha=0.6, beta=0.3, gamma=0.1):\n",
    "    c1 = corr_matrix.loc[a, b]  # correlation under normal\n",
    "    c2 = 1 - corr_during_stress.loc[a, b]  # inverted correlation under stress\n",
    "    vol_ratio = abs(vols[a] - vols[b])\n",
    "    return alpha * c1 + beta * c2 - gamma * vol_ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats.mstats import winsorize\n",
    "\n",
    "# Load prices\n",
    "tickers = ['AAPL', 'GOOG', 'TSLA', 'AMZN', 'META', 'NFLX']\n",
    "prices = yf.download(tickers, start=\"2024-06-01\", end=\"2025-06-01\")['Adj Close']\n",
    "returns = prices.pct_change().dropna()\n",
    "\n",
    "# Winsorize returns to reduce impact of outliers\n",
    "winsorized_returns = returns.apply(lambda x: pd.Series(winsorize(x, limits=[0.1, 0.1]).data, index=x.index))\n",
    "\n",
    "# Basic correlation matrix (Pearson)\n",
    "corr_matrix = winsorized_returns.corr()\n",
    "\n",
    "# Define regime classification\n",
    "regime_matrix = pd.DataFrame(index=corr_matrix.index, columns=corr_matrix.columns)\n",
    "\n",
    "for a in corr_matrix.columns:\n",
    "    for b in corr_matrix.columns:\n",
    "        if a == b:\n",
    "            regime_matrix.loc[a, b] = \"self\"\n",
    "        else:\n",
    "            corr = corr_matrix.loc[a, b]\n",
    "            if corr > 0.6:\n",
    "                regime_matrix.loc[a, b] = \"risk-off\"\n",
    "            elif corr < -0.6:\n",
    "                regime_matrix.loc[a, b] = \"unstable\"\n",
    "            else:\n",
    "                regime_matrix.loc[a, b] = \"baseline\"\n",
    "\n",
    "# Optional: rolling correlation over time (not yet used in this static version)\n",
    "rolling_corrs = winsorized_returns.rolling(21).corr()\n",
    "\n",
    "# Alternative: Kendall’s tau for non-Gaussian behavior\n",
    "kendall_corr = winsorized_returns.corr(method='kendall')\n",
    "\n",
    "# Stress-based weighting\n",
    "weights = (returns < -0.05).astype(int) * 2 + 1\n",
    "weighted_corr = winsorized_returns.mul(weights).corr()\n",
    "\n",
    "# Stress-period-only correlation matrix\n",
    "stress_periods = returns < -0.05\n",
    "corr_during_stress = winsorized_returns[stress_periods.any(axis=1)].corr()\n",
    "\n",
    "# Volatility for each asset\n",
    "vols = winsorized_returns.std()\n",
    "\n",
    "# Pair scoring function\n",
    "def pair_score(a, b, alpha=0.6, beta=0.3, gamma=0.1):\n",
    "    c1 = corr_matrix.loc[a, b]\n",
    "    c2 = 1 - corr_during_stress.loc[a, b]\n",
    "    vol_ratio = abs(vols[a] - vols[b])\n",
    "    return alpha * c1 + beta * c2 - gamma * vol_ratio\n",
    "\n",
    "# Find top-scoring uncorrelated pairs\n",
    "def find_low_corr_pairs(corr_matrix, threshold=0.3):\n",
    "    pairs = []\n",
    "    for i, a in enumerate(corr_matrix.columns):\n",
    "        for j in range(i + 1, len(corr_matrix.columns)):\n",
    "            b = corr_matrix.columns[j]\n",
    "            corr = corr_matrix.loc[a, b]\n",
    "            if abs(corr) < threshold:\n",
    "                score = pair_score(a, b)\n",
    "                pairs.append((a, b, corr, score))\n",
    "    return sorted(pairs, key=lambda x: x[3])\n",
    "\n",
    "# Final result\n",
    "low_corr_pairs = find_low_corr_pairs(corr_matrix)\n",
    "for p in low_corr_pairs:\n",
    "    print(f\"Pair: {p[0]} & {p[1]} | Corr: {p[2]:.3f} | Score: {p[3]:.3f}\")\n",
    "\n",
    "# That regime-tracking logic written out over time?\n",
    "# A full notebook version with heatmaps?\n",
    "# A scoring function that inverts weights during drawdowns (i.e., reward negative correlation when others go up)?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
